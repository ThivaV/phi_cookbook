# Microsoft Phi LLM Cookbook

Microsoft has developed a series of small language models (SLMs) under the **Phi** family. Here are the versions available:

1. **Phi-1**: The initial model with 1.3 billion parameters, optimized for Python coding and common sense reasoning.
2. **Phi-1.5**: An extension of Phi-1 with improved performance on language understanding and reasoning.
3. **Phi-2**: A 2.7 billion-parameter model showcasing state-of-the-art performance on various benchmarks.
4. **Phi-3**: The latest addition, featuring models like Phi-3-mini (3.8 billion parameters), Phi-3-small (7 billion parameters), and Phi-3-medium (14 billion parameters).
5. **Phi-4**: Phi-4 is the latest addition to Microsoft's Phi small language models (SLMs) series

These models are designed to be highly capable and cost-effective, offering performance comparable to much larger models. 
They are available on platforms like **Azure AI Studio**, **Hugging Face**, and **Ollama**.

- Phi-4:
	- Phi-4 represents a significant advancement in small language models, focusing on efficiency and reasoning capabilities. 
	- Key Features:
		- **14 Billion Parameters**: Phi-4 boasts 14 billion parameters, making it highly capable for complex reasoning tasks.
		- **Advanced Reasoning**: It excels in tasks such as STEM question-answering and advanced problem-solving.
		- **Training Approach**: Phi-4 uses a combination of synthetic datasets, curated organic data, and innovative post-training techniques.
		- **Performance**: It has achieved an impressive score of 80.4 on the MATH benchmark, surpassing other models in reasoning evaluations.
		- **Availability**: Phi-4 is available on Azure AI Foundry under the Microsoft Research License Agreement and will soon be available on HuggingFace.
	- Strengths:
		- **Structured Data Handling**: Excellent at extracting detailed and accurate information from complex datasets AI Model Tested Locally: Performance, Limitations and Future Potential](https://www.geeky-gadgets.com/microsofts-phi-4-14b-ai-model/).
		- **Code Generation**: Capable of generating clean, well-formatted code, making it useful for developers AI Model Tested Locally: Performance, Limitations and Future Potential](https://www.geeky-gadgets.com/microsofts-phi-4-14b-ai-model/).
		- **Efficiency**: Balances size and performance, challenging the trend of prioritizing larger models.
	- Limitations:
		- **Inconsistencies**: Some struggles with accuracy and consistency, particularly with coding challenges and financial data summarization AI Model Tested Locally: Performance, Limitations and Future Potential](https://www.geeky-gadgets.com/microsofts-phi-4-14b-ai-model/).
		- **Response Times**: Slower response times for larger inputs AI Model Tested Locally: Performance, Limitations and Future Potential](https://www.geeky-gadgets.com/microsofts-phi-4-14b-ai-model/).
	- Applications:
		- **Scientific Computation**: Ideal for tasks requiring high precision and structured outputs.
		- **STEM Problem-Solving**: Suitable for advanced reasoning tasks in STEM fields.

- References:
	- [Introducing Phi-4: Microsoft’s Newest Small Language Model Specializing in Complex Reasoning](https://techcommunity.microsoft.com/blog/aiplatformblog/introducing-phi-4-microsoft’s-newest-small-language-model-specializing-in-comple/4357090)
	- [Microsoft unveils Phi-4](https://www.fudzilla.com/news/ai/60254-microsoft-unveils-phi-4?form=MG0AV3)
	- [Microsoft’s Phi-4 (14B) AI Model Tested Locally: Performance, Limitations and Future Potential](https://www.geeky-gadgets.com/microsofts-phi-4-14b-ai-model/?form=MG0AV3)